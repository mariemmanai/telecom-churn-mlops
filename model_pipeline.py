# model_pipeline.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import joblib
import os

def load_data(train_path, test_path):
    """
    Charger les donnÃ©es d'entraÃ®nement et de test
    
    Args:
        train_path (str): Chemin vers le fichier d'entraÃ®nement
        test_path (str): Chemin vers le fichier de test
    
    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    try:
        X_train = pd.read_csv(train_path)
        X_test = pd.read_csv(test_path)
        print("âœ… DonnÃ©es chargÃ©es avec succÃ¨s")
        print(f"ğŸ“Š Shape train: {X_train.shape}, test: {X_test.shape}")
        return X_train, X_test
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")
        return None, None

def explore_data(df, name="Dataset"):
    """
    Exploration basique des donnÃ©es
    """
    print(f"\nğŸ” Exploration de {name}:")
    print(f"Shape: {df.shape}")
    print("\nğŸ“ˆ Informations basiques:")
    print(df.info())
    print("\nğŸ“Š Statistiques descriptives:")
    print(df.describe())
    print("\nğŸ¯ Variable cible 'Churn':")
    print(df['Churn'].value_counts())
    
    return df

def prepare_data(X_train, X_test):
    """
    PrÃ©traiter les donnÃ©es : nettoyage, encodage, feature engineering
    """
    print("\nğŸ”„ DÃ©but du prÃ©traitement des donnÃ©es...")
    
    # SÃ©parer features et target
    y_train = X_train['Churn']
    y_test = X_test['Churn']
    
    # Supprimer la colonne target des features
    X_train = X_train.drop('Churn', axis=1)
    X_test = X_test.drop('Churn', axis=1)
    
    # 1. Encodage des variables catÃ©gorielles
    categorical_cols = ['State', 'International plan', 'Voice mail plan']
    
    # Encoder International plan et Voice mail plan
    X_train['International plan'] = X_train['International plan'].map({'No': 0, 'Yes': 1})
    X_test['International plan'] = X_test['International plan'].map({'No': 0, 'Yes': 1})
    
    X_train['Voice mail plan'] = X_train['Voice mail plan'].map({'No': 0, 'Yes': 1})
    X_test['Voice mail plan'] = X_test['Voice mail plan'].map({'No': 0, 'Yes': 1})
    
    # One-Hot Encoding pour State
    X_train = pd.get_dummies(X_train, columns=['State'], prefix='State')
    X_test = pd.get_dummies(X_test, columns=['State'], prefix='State')
    
    # 2. Feature Engineering (comme dans votre notebook)
    X_train['Total calls'] = X_train['Total day calls'] + X_train['Total eve calls'] + X_train['Total night calls'] + X_train['Total intl calls']
    X_train['Total charge'] = X_train['Total day charge'] + X_train['Total eve charge'] + X_train['Total night charge'] + X_train['Total intl charge']
    X_train['CS calls Rate'] = X_train['Customer service calls'] / X_train['Account length']
    
    X_test['Total calls'] = X_test['Total day calls'] + X_test['Total eve calls'] + X_test['Total night calls'] + X_test['Total intl calls']
    X_test['Total charge'] = X_test['Total day charge'] + X_test['Total eve charge'] + X_test['Total night charge'] + X_test['Total intl charge']
    X_test['CS calls Rate'] = X_test['Customer service calls'] / X_test['Account length']
    
    print("âœ… PrÃ©traitement terminÃ©")
    print(f"ğŸ“Š Nouvelles shapes - Train: {X_train.shape}, Test: {X_test.shape}")
    
    return X_train, X_test, y_train, y_test

def train_model(X_train, y_train, model_type='random_forest'):
    """
    EntraÃ®ner un modÃ¨le de machine learning
    
    Args:
        X_train: Features d'entraÃ®nement
        y_train: Target d'entraÃ®nement
        model_type: Type de modÃ¨le ('random_forest', 'gradient_boosting')
    
    Returns:
        model: ModÃ¨le entraÃ®nÃ©
    """
    print(f"\nğŸ¯ EntraÃ®nement du modÃ¨le: {model_type}")
    
    if model_type == 'random_forest':
        model = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            class_weight='balanced'
        )
    elif model_type == 'gradient_boosting':
        model = GradientBoostingClassifier(
            n_estimators=100,
            random_state=42
        )
    else:
        raise ValueError("ModÃ¨le non supportÃ©")
    
    model.fit(X_train, y_train)
    print("âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s")
    
    return model

def evaluate_model(model, X_test, y_test):
    """
    Ã‰valuer les performances du modÃ¨le
    """
    print("\nğŸ“Š Ã‰valuation du modÃ¨le...")
    
    # PrÃ©dictions
    y_pred = model.predict(X_test)
    
    # MÃ©triques
    accuracy = accuracy_score(y_test, y_pred)
    print(f"âœ… Accuracy: {accuracy:.4f}")
    
    print("\nğŸ“‹ Rapport de classification:")
    print(classification_report(y_test, y_pred))
    
    print("\nğŸ¯ Matrice de confusion:")
    print(confusion_matrix(y_test, y_pred))
    
    return accuracy

def save_model(model, filepath):
    """
    Sauvegarder le modÃ¨le entraÃ®nÃ©
    """
    # CrÃ©er le dossier models s'il n'existe pas
    os.makedirs('models', exist_ok=True)
    
    joblib.dump(model, filepath)
    print(f"âœ… ModÃ¨le sauvegardÃ©: {filepath}")

def load_model(filepath):
    """
    Charger un modÃ¨le sauvegardÃ©
    """
    model = joblib.load(filepath)
    print(f"âœ… ModÃ¨le chargÃ©: {filepath}")
    return model

if __name__ == "__main__":
    # Test des fonctions
    print("ğŸ§ª Test du module model_pipeline...")